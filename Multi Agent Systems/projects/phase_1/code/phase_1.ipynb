{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19e77b88",
      "metadata": {
        "id": "19e77b88"
      },
      "outputs": [],
      "source": [
        "!pip install langchain_google_genai\n",
        "!pip install -U langchain\n",
        "!pip install requests beautifulsoup4\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4d3b6cc",
      "metadata": {
        "id": "d4d3b6cc"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from typing import List, Dict, Tuple\n",
        "import re\n",
        "import json\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8YlQham-5Bsu",
      "metadata": {
        "cellView": "form",
        "id": "8YlQham-5Bsu"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "#@title CategorizerAgent Class\n",
        "class ExtractorAgent:\n",
        "    \"\"\"\n",
        "    Agent 1: Responsible for extracting the list of papers from GitHub.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, llm):\n",
        "        self.llm = llm\n",
        "        self.github_urls = [\n",
        "            \"https://github.com/kyegomez/awesome-multi-agent-papers\",\n",
        "            \"https://github.com/shizhl/Multi-Agent-Papers\",\n",
        "        ]\n",
        "\n",
        "    def fetch_github_content(self, url: str) -> str:\n",
        "        \"\"\"\n",
        "        Fetch the HTML content of a GitHub page.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            response = requests.get(url)\n",
        "            response.raise_for_status()\n",
        "            return response.text\n",
        "        except Exception as e:\n",
        "            print(f\"Error while fetching {url}: {e}\")\n",
        "            return \"\"\n",
        "\n",
        "    def extract_paper_titles(self, html_content: str) -> List[str]:\n",
        "        \"\"\"\n",
        "        Extract paper titles from HTML.\n",
        "        \"\"\"\n",
        "        soup = BeautifulSoup(html_content, \"html.parser\")\n",
        "\n",
        "        # Collect all paper links/titles\n",
        "        papers: List[str] = []\n",
        "\n",
        "        # Method 1: Find bold text, which often corresponds to paper titles\n",
        "        for strong in soup.find_all(\"strong\"):\n",
        "            text = strong.get_text().strip()\n",
        "            # Filter out headers\n",
        "            if len(text) > 10 and not text.startswith(\"#\"):\n",
        "                papers.append(text)\n",
        "\n",
        "        # Method 2: Find links that point to arxiv or PDF files\n",
        "        for link in soup.find_all(\"a\", href=True):\n",
        "            href = link[\"href\"]\n",
        "            if \"arxiv.org\" in href or \"pdf\" in href.lower():\n",
        "                text = link.get_text().strip()\n",
        "                if text and len(text) > 10:\n",
        "                    papers.append(text)\n",
        "\n",
        "        # Remove duplicates\n",
        "        return list(set(papers))\n",
        "\n",
        "    def categorize_papers_with_llm(self, papers: List[str]) -> Dict:\n",
        "        \"\"\"\n",
        "        Use the LLM to get a first, coarse-grained categorization of papers.\n",
        "        \"\"\"\n",
        "        # Limit to first 50 papers for the LLM prompt\n",
        "        papers_text = \"\\n\".join(\n",
        "            [f\"{i + 1}. {paper}\" for i, paper in enumerate(papers[:50])]\n",
        "        )\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "You are an expert in Multi-Agent Systems.\n",
        "You have received the following list of paper titles.\n",
        "\n",
        "Papers:\n",
        "{papers_text}\n",
        "\n",
        "Please:\n",
        "1. Identify the main topic of each paper.\n",
        "2. Group the papers into high-level categories (e.g., Collaboration, Frameworks, Healthcare, Coding, etc.).\n",
        "3. Output ONLY the category names and the number of papers in each category.\n",
        "\n",
        "Output format:\n",
        "- Category Name: Count\n",
        "\"\"\"\n",
        "\n",
        "        response = self.llm.invoke(prompt)\n",
        "        return response.content\n",
        "\n",
        "    def run(self) -> List[str]:\n",
        "        \"\"\"\n",
        "        Run Agent 1 end-to-end.\n",
        "        \"\"\"\n",
        "        print(\"üîç Agent 1 (Extractor) started...\\n\")\n",
        "\n",
        "        all_papers: List[str] = []\n",
        "\n",
        "        for url in self.github_urls:\n",
        "            print(f\"üì• Fetching: {url}\")\n",
        "            html = self.fetch_github_content(url)\n",
        "\n",
        "            if html:\n",
        "                papers = self.extract_paper_titles(html)\n",
        "                all_papers.extend(papers)\n",
        "                print(f\"‚úÖ Number of extracted papers: {len(papers)}\\n\")\n",
        "\n",
        "        print(f\"üìä Total extracted papers (including duplicates): {len(all_papers)}\\n\")\n",
        "\n",
        "        # Remove duplicates\n",
        "        unique_papers = list(set(all_papers))\n",
        "        print(f\"üìä Number of unique papers: {len(unique_papers)}\\n\")\n",
        "\n",
        "        # Show first 10 samples\n",
        "        print(\"üîñ Sample papers:\")\n",
        "        for i, paper in enumerate(unique_papers[:10], 1):\n",
        "            print(f\"   {i}. {paper}\")\n",
        "\n",
        "        return unique_papers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f8ffe3f",
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "0f8ffe3f",
        "outputId": "d7fa9c9a-06c0-4d1f-a48f-3b793bdb63b2"
      },
      "outputs": [],
      "source": [
        "#@title Run Agent 1\n",
        "extractor = ExtractorAgent(llm)\n",
        "papers = extractor.run()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b08ab55e",
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "b08ab55e",
        "outputId": "d157f317-fee3-44db-e660-33c3d2ade9e2"
      },
      "outputs": [],
      "source": [
        "#@title Save results for the next Agent\n",
        "print(\"\\n‚úÖ Agent 1 finished!\")\n",
        "print(f\"üì¶ Total number of papers: {len(papers)}\")\n",
        "print(\"üì§ Ready for Agent 2 (Categorizer)\")\n",
        "\n",
        "# Save to file\n",
        "with open(\"extracted_papers.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for paper in papers:\n",
        "        f.write(paper + \"\\n\")\n",
        "\n",
        "print(\"\\nüíæ File 'extracted_papers.txt' has been saved.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "E8fnQm6q5MYl",
      "metadata": {
        "cellView": "form",
        "id": "E8fnQm6q5MYl"
      },
      "outputs": [],
      "source": [
        "#@title CategorizerAgent\n",
        "class CategorizerAgent:\n",
        "    \"\"\"\n",
        "    Agent 2: Categorize papers into main research topics.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, llm):\n",
        "        self.llm = llm\n",
        "\n",
        "        # Main categories based on inspection of GitHub lists\n",
        "        self.main_categories: Dict[str, str] = {\n",
        "            \"Multi-Agent Collaboration\": \"Collaboration and coordination between agents\",\n",
        "            \"Frameworks & Tools\": \"Frameworks and development tools\",\n",
        "            \"Software Engineering\": \"Software engineering and coding applications\",\n",
        "            \"Healthcare & Medical\": \"Medical and healthcare applications\",\n",
        "            \"Data & ML\": \"Data analysis and machine learning\",\n",
        "            \"Evaluation & Benchmarks\": \"Evaluation and benchmarking\",\n",
        "            \"Social Simulation\": \"Social simulation and human behavior\",\n",
        "            \"Reasoning & Problem Solving\": \"Reasoning and problem solving\",\n",
        "            \"Communication\": \"Communication and information exchange\",\n",
        "            \"Architecture & Design\": \"System architecture and design\",\n",
        "            \"Security\": \"Cybersecurity\",\n",
        "            \"Multimodal\": \"Multimodal systems\",\n",
        "            \"Other Applications\": \"Other applications\",\n",
        "        }\n",
        "\n",
        "    def categorize_single_paper(self, paper_title: str) -> str:\n",
        "        \"\"\"\n",
        "        Categorize a single paper using the LLM.\n",
        "        \"\"\"\n",
        "        categories_list = \"\\n\".join(\n",
        "            [f\"- {cat}: {desc}\" for cat, desc in self.main_categories.items()]\n",
        "        )\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "You are an expert in Multi-Agent Systems research.\n",
        "\n",
        "Given this paper title:\n",
        "\"{paper_title}\"\n",
        "\n",
        "Assign it to ONE of these categories:\n",
        "{categories_list}\n",
        "\n",
        "Return ONLY the category name (e.g., \"Multi-Agent Collaboration\"), nothing else.\n",
        "\"\"\"\n",
        "\n",
        "        try:\n",
        "            response = self.llm.invoke(prompt)\n",
        "            category = response.content.strip()\n",
        "\n",
        "            # If the returned category is not in the list, map it to the closest or Other\n",
        "            if category not in self.main_categories:\n",
        "                for cat in self.main_categories.keys():\n",
        "                    if cat.lower() in category.lower():\n",
        "                        return cat\n",
        "                return \"Other Applications\"\n",
        "\n",
        "            return category\n",
        "        except Exception as e:\n",
        "            print(f\"Error while classifying '{paper_title}': {e}\")\n",
        "            return \"Other Applications\"\n",
        "\n",
        "    def categorize_batch(self, papers: List[str], batch_size: int = 10) -> Dict[str, List[str]]:\n",
        "        \"\"\"\n",
        "        Batch categorization of papers (faster, fewer API calls).\n",
        "        \"\"\"\n",
        "        print(f\"üìä Starting categorization of {len(papers)} papers...\\n\")\n",
        "\n",
        "        categorized: Dict[str, List[str]] = {cat: [] for cat in self.main_categories.keys()}\n",
        "\n",
        "        for i in range(0, len(papers), batch_size):\n",
        "            batch = papers[i : i + batch_size]\n",
        "\n",
        "            papers_text = \"\\n\".join([f\"{j + 1}. {paper}\" for j, paper in enumerate(batch)])\n",
        "\n",
        "            prompt = f\"\"\"\n",
        "You are an expert in Multi-Agent Systems research.\n",
        "\n",
        "Categorize each paper below into ONE category from this list:\n",
        "{', '.join(self.main_categories.keys())}\n",
        "\n",
        "Papers:\n",
        "{papers_text}\n",
        "\n",
        "Return your answer in this EXACT format (one per line):\n",
        "1. Category Name\n",
        "2. Category Name\n",
        "...\n",
        "\n",
        "Example:\n",
        "1. Multi-Agent Collaboration\n",
        "2. Software Engineering\n",
        "\"\"\"\n",
        "\n",
        "            try:\n",
        "                response = self.llm.invoke(prompt)\n",
        "                categories = response.content.strip().split(\"\\n\")\n",
        "\n",
        "                for idx, category_line in enumerate(categories):\n",
        "                    if idx >= len(batch):\n",
        "                        break\n",
        "\n",
        "                    # Extract category name from \"N. Category Name\"\n",
        "                    category = category_line.split(\". \", 1)[-1].strip()\n",
        "\n",
        "                    # Validate category\n",
        "                    if category in self.main_categories:\n",
        "                        categorized[category].append(batch[idx])\n",
        "                    else:\n",
        "                        # Try to find the closest category\n",
        "                        found = False\n",
        "                        for cat in self.main_categories.keys():\n",
        "                            if cat.lower() in category.lower():\n",
        "                                categorized[cat].append(batch[idx])\n",
        "                                found = True\n",
        "                                break\n",
        "                        if not found:\n",
        "                            categorized[\"Other Applications\"].append(batch[idx])\n",
        "\n",
        "                print(\n",
        "                    f\"‚úÖ Classified {min(i + batch_size, len(papers))} \"\n",
        "                    f\"out of {len(papers)} papers\"\n",
        "                )\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"‚ö†Ô∏è Error in batch {i // batch_size + 1}: {e}\")\n",
        "                # If something fails, put all papers in this batch into Other\n",
        "                for paper in batch:\n",
        "                    categorized[\"Other Applications\"].append(paper)\n",
        "\n",
        "        return categorized\n",
        "\n",
        "    def generate_statistics(self, categorized: Dict[str, List[str]]) -> Dict:\n",
        "        \"\"\"\n",
        "        Generate statistics (count, percentage, description) for each category.\n",
        "        \"\"\"\n",
        "        stats: Dict[str, Dict] = {}\n",
        "        total = sum(len(ps) for ps in categorized.values())\n",
        "\n",
        "        for category, ps in categorized.items():\n",
        "            count = len(ps)\n",
        "            percentage = (count / total * 100) if total > 0 else 0.0\n",
        "            stats[category] = {\n",
        "                \"count\": count,\n",
        "                \"percentage\": round(percentage, 2),\n",
        "                \"description\": self.main_categories[category],\n",
        "            }\n",
        "\n",
        "        return stats\n",
        "\n",
        "    def run(self, papers: List[str], batch_size: int = 10) -> Tuple[Dict[str, List[str]], Dict[str, Dict]]:\n",
        "        \"\"\"\n",
        "        Run Agent 2 end-to-end.\n",
        "\n",
        "        Args:\n",
        "            papers: List of paper titles\n",
        "            batch_size: Number of papers per batch (default: 10)\n",
        "        \"\"\"\n",
        "        print(\"üîç Agent 2 (Categorizer) started...\\n\")\n",
        "        print(f\"üì¶ Batch size: {batch_size}\\n\")\n",
        "\n",
        "        # Categorize all papers with custom batch_size\n",
        "        categorized = self.categorize_batch(papers, batch_size=batch_size)  # ‚Üê ÿ≠ÿßŸÑÿß ŸÇÿßÿ®ŸÑ ÿ™ŸÜÿ∏€åŸÖ!\n",
        "\n",
        "        # Compute statistics\n",
        "        stats = self.generate_statistics(categorized)\n",
        "\n",
        "\n",
        "        # Print results\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"üìä Categorization results:\")\n",
        "        print(\"=\" * 60 + \"\\n\")\n",
        "\n",
        "        # Sort by count (descending)\n",
        "        sorted_stats = sorted(stats.items(), key=lambda x: x[1][\"count\"], reverse=True)\n",
        "\n",
        "        for category, data in sorted_stats:\n",
        "            if data[\"count\"] > 0:\n",
        "                print(f\"üìÅ {category}\")\n",
        "                print(f\"   Count: {data['count']} ({data['percentage']}%)\")\n",
        "                print(f\"   Description: {data['description']}\\n\")\n",
        "\n",
        "        return categorized, stats\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa-yi_10Hhji",
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "fa-yi_10Hhji",
        "outputId": "ac405bf8-abbc-4d49-e065-4955cf147843"
      },
      "outputs": [],
      "source": [
        "#@title run agent 2\n",
        "\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# Initialize model with gemini-2.5-flash\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    api_key=\"AIzaSxxxxxxyOH6cAels\",\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "print(\"üöÄ Starting categorization with gemini-2.5-flash\")\n",
        "print(f\"   Papers: {len(papers)}\")\n",
        "print(f\"   Batch size: 30\")\n",
        "print(f\"   Expected batches: 8\\n\")\n",
        "\n",
        "# Run categorization\n",
        "categorizer = CategorizerAgent(llm)\n",
        "categorized_papers, statistics = categorizer.run(papers, batch_size=30)\n",
        "\n",
        "# Save results\n",
        "import json\n",
        "\n",
        "with open('categorized_papers_final.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(categorized_papers, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "with open('statistics_final.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(statistics, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"‚úÖ All papers categorized successfully!\")\n",
        "print(\"üíæ Files saved:\")\n",
        "print(\"   - categorized_papers_final.json\")\n",
        "print(\"   - statistics_final.json\")\n",
        "print(\"\\nüéØ Ready for Agent 3!\")\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29dd5a0c",
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "29dd5a0c",
        "outputId": "d5bb9f2a-d702-4548-b1dd-a1e435b7bc22"
      },
      "outputs": [],
      "source": [
        "#@title Save results for later use\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"üíæ Saving results...\")\n",
        "print(\"=\" * 60 + \"\\n\")\n",
        "\n",
        "# Save as JSON\n",
        "with open(\"categorized_papers.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(categorized_papers, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "with open(\"statistics.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(statistics, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(\"‚úÖ The following files have been saved:\")\n",
        "print(\"   - categorized_papers.json (categorized papers)\")\n",
        "print(\"   - statistics.json (category statistics)\")\n",
        "\n",
        "print(\"\\nüìä Final summary:\")\n",
        "print(f\"   - Total number of papers: {len(papers)}\")\n",
        "print(f\"   - Number of non-empty categories: {len([s for s in statistics.values() if s['count'] > 0])}\")\n",
        "print(\"\\n‚úÖ Agent 2 has finished!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd41ed9e",
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 604
        },
        "collapsed": true,
        "id": "fd41ed9e",
        "outputId": "04c951d2-c886-4327-a970-22b31e4a3792"
      },
      "outputs": [],
      "source": [
        "#@title Generate output for plotting\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def visualize_categories(statistics: Dict):\n",
        "    \"\"\"\n",
        "    Plot category distribution.\n",
        "    \"\"\"\n",
        "    # Filter out empty categories\n",
        "    filtered = {k: v[\"count\"] for k, v in statistics.items() if v[\"count\"] > 0}\n",
        "\n",
        "    # Sort by count (descending)\n",
        "    sorted_data = dict(sorted(filtered.items(), key=lambda x: x[1], reverse=True))\n",
        "\n",
        "    # Bar chart\n",
        "    plt.figure(figsize=(14, 8))\n",
        "    bars = plt.bar(\n",
        "        range(len(sorted_data)),\n",
        "        list(sorted_data.values()),\n",
        "        color=\"steelblue\",\n",
        "    )\n",
        "    plt.xticks(\n",
        "        range(len(sorted_data)),\n",
        "        list(sorted_data.keys()),\n",
        "        rotation=45,\n",
        "        ha=\"right\",\n",
        "    )\n",
        "    plt.xlabel(\"Category\", fontsize=12)\n",
        "    plt.ylabel(\"Number of papers\", fontsize=12)\n",
        "    plt.title(\n",
        "        \"Distribution of Papers across LLM Multi-Agent Categories\",\n",
        "        fontsize=14,\n",
        "        fontweight=\"bold\",\n",
        "    )\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Add value labels on bars\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        plt.text(\n",
        "            bar.get_x() + bar.get_width() / 2.0,\n",
        "            height,\n",
        "            f\"{int(height)}\",\n",
        "            ha=\"center\",\n",
        "            va=\"bottom\",\n",
        "            fontsize=10,\n",
        "        )\n",
        "\n",
        "    plt.savefig(\"paper_distribution.png\", dpi=300, bbox_inches=\"tight\")\n",
        "    print(\"\\nüìä Chart saved as 'paper_distribution.png'\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Draw chart\n",
        "visualize_categories(statistics)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0aa21e6",
      "metadata": {
        "id": "a0aa21e6"
      },
      "outputs": [],
      "source": [
        "# Install squarify for treemap (if not already installed)\n",
        "!pip install squarify -q\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rYRSrBcEv_m9",
      "metadata": {
        "id": "rYRSrBcEv_m9"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import textwrap\n",
        "from typing import Dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zB0hECOlwAhF",
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "zB0hECOlwAhF",
        "outputId": "39e8b554-8000-4d2f-907e-f3067cc04409"
      },
      "outputs": [],
      "source": [
        "#@title ReporterAgent\n",
        "class ReporterAgent:\n",
        "    \"\"\"\n",
        "    Agent 3: Generate a comprehensive report with various charts and textual analysis.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, llm):\n",
        "        self.llm = llm\n",
        "        self.output_dir = \"report_output\"\n",
        "\n",
        "        # Create output directory if it does not exist\n",
        "        import os\n",
        "        if not os.path.exists(self.output_dir):\n",
        "            os.makedirs(self.output_dir)\n",
        "\n",
        "        # Font settings (optional ‚Äì useful for Persian text in plots)\n",
        "        plt.rcParams[\"font.family\"] = \"DejaVu Sans\"\n",
        "\n",
        "    def plot_bar_chart(self, statistics: Dict, filename: str = \"bar_chart.png\"):\n",
        "        \"\"\"\n",
        "        Vertical bar chart with a professional design.\n",
        "        \"\"\"\n",
        "        filtered = {k: v[\"count\"] for k, v in statistics.items() if v[\"count\"] > 0}\n",
        "        sorted_data = dict(\n",
        "            sorted(filtered.items(), key=lambda x: x[1], reverse=True)\n",
        "        )\n",
        "\n",
        "        plt.figure(figsize=(16, 10))\n",
        "        colors = plt.cm.viridis(np.linspace(0.3, 0.9, len(sorted_data)))\n",
        "\n",
        "        bars = plt.bar(\n",
        "            range(len(sorted_data)),\n",
        "            list(sorted_data.values()),\n",
        "            color=colors,\n",
        "            edgecolor=\"black\",\n",
        "            linewidth=1.5,\n",
        "            alpha=0.8,\n",
        "        )\n",
        "\n",
        "        plt.xticks(\n",
        "            range(len(sorted_data)),\n",
        "            [textwrap.fill(label, 15) for label in sorted_data.keys()],\n",
        "            rotation=45,\n",
        "            ha=\"right\",\n",
        "            fontsize=11,\n",
        "        )\n",
        "        plt.ylabel(\"Number of Papers\", fontsize=14, fontweight=\"bold\")\n",
        "        plt.xlabel(\"Category\", fontsize=14, fontweight=\"bold\")\n",
        "        plt.title(\n",
        "            \"Distribution of Multi-Agent LLM Papers by Category\",\n",
        "            fontsize=16,\n",
        "            fontweight=\"bold\",\n",
        "            pad=20,\n",
        "        )\n",
        "        plt.grid(axis=\"y\", alpha=0.3, linestyle=\"--\")\n",
        "\n",
        "        # Add value labels on top of bars\n",
        "        for bar in bars:\n",
        "            height = bar.get_height()\n",
        "            plt.text(\n",
        "                bar.get_x() + bar.get_width() / 2.0,\n",
        "                height,\n",
        "                f\"{int(height)}\",\n",
        "                ha=\"center\",\n",
        "                va=\"bottom\",\n",
        "                fontsize=11,\n",
        "                fontweight=\"bold\",\n",
        "            )\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f\"{self.output_dir}/{filename}\", dpi=300, bbox_inches=\"tight\")\n",
        "        plt.close()\n",
        "        print(f\"  ‚úÖ {filename}\")\n",
        "\n",
        "    def plot_pie_chart(self, statistics: Dict, filename: str = \"pie_chart.png\"):\n",
        "        \"\"\"\n",
        "        Pie chart of category distribution.\n",
        "        \"\"\"\n",
        "        filtered = {k: v[\"count\"] for k, v in statistics.items() if v[\"count\"] > 0}\n",
        "        sorted_data = dict(\n",
        "            sorted(filtered.items(), key=lambda x: x[1], reverse=True)\n",
        "        )\n",
        "\n",
        "        # Top 8 categories + Others\n",
        "        top_8 = dict(list(sorted_data.items())[:8])\n",
        "        others_count = sum(list(sorted_data.values())[8:])\n",
        "        if others_count > 0:\n",
        "            top_8[\"Others\"] = others_count\n",
        "\n",
        "        plt.figure(figsize=(14, 10))\n",
        "        colors = plt.cm.Set3(np.linspace(0, 1, len(top_8)))\n",
        "\n",
        "        wedges, texts, autotexts = plt.pie(\n",
        "            top_8.values(),\n",
        "            labels=[textwrap.fill(k, 20) for k in top_8.keys()],\n",
        "            autopct=\"%1.1f%%\",\n",
        "            colors=colors,\n",
        "            startangle=90,\n",
        "            textprops={\"fontsize\": 11, \"weight\": \"bold\"},\n",
        "            explode=[0.05] * len(top_8),  # separate slices slightly\n",
        "        )\n",
        "\n",
        "        # Improve readability of percentage labels\n",
        "        for autotext in autotexts:\n",
        "            autotext.set_color(\"white\")\n",
        "            autotext.set_fontsize(12)\n",
        "            autotext.set_weight(\"bold\")\n",
        "\n",
        "        plt.title(\n",
        "            \"Category Distribution (Top 8 + Others)\",\n",
        "            fontsize=16,\n",
        "            fontweight=\"bold\",\n",
        "            pad=20,\n",
        "        )\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f\"{self.output_dir}/{filename}\", dpi=300, bbox_inches=\"tight\")\n",
        "        plt.close()\n",
        "        print(f\"  ‚úÖ {filename}\")\n",
        "\n",
        "    def plot_horizontal_bar(self, statistics: Dict, filename: str = \"horizontal_bar.png\"):\n",
        "        \"\"\"\n",
        "        Horizontal bar chart for easier comparison.\n",
        "        \"\"\"\n",
        "        filtered = {k: v[\"count\"] for k, v in statistics.items() if v[\"count\"] > 0}\n",
        "        sorted_data = dict(sorted(filtered.items(), key=lambda x: x[1]))\n",
        "\n",
        "        plt.figure(figsize=(12, 10))\n",
        "        colors = plt.cm.coolwarm(np.linspace(0.2, 0.8, len(sorted_data)))\n",
        "\n",
        "        bars = plt.barh(\n",
        "            range(len(sorted_data)),\n",
        "            list(sorted_data.values()),\n",
        "            color=colors,\n",
        "            edgecolor=\"black\",\n",
        "            linewidth=1.2,\n",
        "            alpha=0.85,\n",
        "        )\n",
        "\n",
        "        plt.yticks(\n",
        "            range(len(sorted_data)),\n",
        "            [textwrap.fill(label, 35) for label in sorted_data.keys()],\n",
        "            fontsize=11,\n",
        "        )\n",
        "        plt.xlabel(\"Number of Papers\", fontsize=14, fontweight=\"bold\")\n",
        "        plt.title(\n",
        "            \"Papers Count by Category (Horizontal View)\",\n",
        "            fontsize=16,\n",
        "            fontweight=\"bold\",\n",
        "            pad=20,\n",
        "        )\n",
        "        plt.grid(axis=\"x\", alpha=0.3, linestyle=\"--\")\n",
        "\n",
        "        # Add value labels\n",
        "        for bar in bars:\n",
        "            width = bar.get_width()\n",
        "            plt.text(\n",
        "                width + 1,\n",
        "                bar.get_y() + bar.get_height() / 2.0,\n",
        "                f\"{int(width)}\",\n",
        "                ha=\"left\",\n",
        "                va=\"center\",\n",
        "                fontsize=10,\n",
        "                fontweight=\"bold\",\n",
        "            )\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f\"{self.output_dir}/{filename}\", dpi=300, bbox_inches=\"tight\")\n",
        "        plt.close()\n",
        "        print(f\"  ‚úÖ {filename}\")\n",
        "\n",
        "    def plot_treemap(self, statistics: Dict, filename: str = \"treemap.png\"):\n",
        "        \"\"\"\n",
        "        Treemap visualization of category proportions.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            import squarify\n",
        "        except ImportError:\n",
        "            print(\"  ‚ö†Ô∏è squarify is not installed. Treemap will not be generated.\")\n",
        "            return\n",
        "\n",
        "        filtered = {k: v[\"count\"] for k, v in statistics.items() if v[\"count\"] > 0}\n",
        "        sorted_data = dict(\n",
        "            sorted(filtered.items(), key=lambda x: x[1], reverse=True)\n",
        "        )\n",
        "\n",
        "        plt.figure(figsize=(16, 10))\n",
        "\n",
        "        sizes = list(sorted_data.values())\n",
        "        labels = [f\"{k}\\n({v})\" for k, v in sorted_data.items()]\n",
        "        colors = plt.cm.Spectral(np.linspace(0.2, 0.8, len(sorted_data)))\n",
        "\n",
        "        squarify.plot(\n",
        "            sizes=sizes,\n",
        "            label=labels,\n",
        "            color=colors,\n",
        "            alpha=0.8,\n",
        "            text_kwargs={\"fontsize\": 10, \"weight\": \"bold\"},\n",
        "            edgecolor=\"white\",\n",
        "            linewidth=3,\n",
        "        )\n",
        "\n",
        "        plt.axis(\"off\")\n",
        "        plt.title(\n",
        "            \"Treemap: Research Areas in Multi-Agent LLM\",\n",
        "            fontsize=18,\n",
        "            fontweight=\"bold\",\n",
        "            pad=20,\n",
        "        )\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f\"{self.output_dir}/{filename}\", dpi=300, bbox_inches=\"tight\")\n",
        "        plt.close()\n",
        "        print(f\"  ‚úÖ {filename}\")\n",
        "\n",
        "    def plot_percentage_comparison(self, statistics: Dict, filename: str = \"percentage_chart.png\"):\n",
        "        \"\"\"\n",
        "        Side-by-side percentage vs absolute count comparison.\n",
        "        \"\"\"\n",
        "        filtered = {k: v for k, v in statistics.items() if v[\"count\"] > 0}\n",
        "        sorted_data = dict(\n",
        "            sorted(filtered.items(), key=lambda x: x[1][\"percentage\"], reverse=True)\n",
        "        )\n",
        "\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 8))\n",
        "\n",
        "        categories = list(sorted_data.keys())\n",
        "        percentages = [v[\"percentage\"] for v in sorted_data.values()]\n",
        "        counts = [v[\"count\"] for v in sorted_data.values()]\n",
        "        colors = plt.cm.plasma(np.linspace(0.2, 0.9, len(categories)))\n",
        "\n",
        "        # Chart 1: Percentages\n",
        "        bars1 = ax1.barh(\n",
        "            categories,\n",
        "            percentages,\n",
        "            color=colors,\n",
        "            edgecolor=\"black\",\n",
        "            linewidth=1.2,\n",
        "            alpha=0.85,\n",
        "        )\n",
        "        ax1.set_xlabel(\"Percentage (%)\", fontsize=12, fontweight=\"bold\")\n",
        "        ax1.set_title(\"Percentage Distribution\", fontsize=14, fontweight=\"bold\")\n",
        "        ax1.grid(axis=\"x\", alpha=0.3)\n",
        "\n",
        "        for i, bar in enumerate(bars1):\n",
        "            width = bar.get_width()\n",
        "            ax1.text(\n",
        "                width + 0.5,\n",
        "                bar.get_y() + bar.get_height() / 2.0,\n",
        "                f\"{percentages[i]:.1f}%\",\n",
        "                ha=\"left\",\n",
        "                va=\"center\",\n",
        "                fontsize=9,\n",
        "                fontweight=\"bold\",\n",
        "            )\n",
        "\n",
        "        # Chart 2: Absolute counts\n",
        "        bars2 = ax2.barh(\n",
        "            categories,\n",
        "            counts,\n",
        "            color=colors,\n",
        "            edgecolor=\"black\",\n",
        "            linewidth=1.2,\n",
        "            alpha=0.85,\n",
        "        )\n",
        "        ax2.set_xlabel(\"Number of Papers\", fontsize=12, fontweight=\"bold\")\n",
        "        ax2.set_title(\"Absolute Count\", fontsize=14, fontweight=\"bold\")\n",
        "        ax2.grid(axis=\"x\", alpha=0.3)\n",
        "\n",
        "        for i, bar in enumerate(bars2):\n",
        "            width = bar.get_width()\n",
        "            ax2.text(\n",
        "                width + 0.5,\n",
        "                bar.get_y() + bar.get_height() / 2.0,\n",
        "                f\"{counts[i]}\",\n",
        "                ha=\"left\",\n",
        "                va=\"center\",\n",
        "                fontsize=9,\n",
        "                fontweight=\"bold\",\n",
        "            )\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f\"{self.output_dir}/{filename}\", dpi=300, bbox_inches=\"tight\")\n",
        "        plt.close()\n",
        "        print(f\"  ‚úÖ {filename}\")\n",
        "\n",
        "    def plot_top_categories_donut(self, statistics: Dict, filename: str = \"donut_chart.png\"):\n",
        "        \"\"\"\n",
        "        Donut chart for the top 5 categories.\n",
        "        \"\"\"\n",
        "        filtered = {k: v[\"count\"] for k, v in statistics.items() if v[\"count\"] > 0}\n",
        "        sorted_data = dict(\n",
        "            sorted(filtered.items(), key=lambda x: x[1], reverse=True)\n",
        "        )\n",
        "\n",
        "        # Top 5 categories only\n",
        "        top_5 = dict(list(sorted_data.items())[:5])\n",
        "\n",
        "        plt.figure(figsize=(12, 10))\n",
        "        colors = [\"#ff9999\", \"#66b3ff\", \"#99ff99\", \"#ffcc99\", \"#ff99cc\"]\n",
        "\n",
        "        wedges, texts, autotexts = plt.pie(\n",
        "            top_5.values(),\n",
        "            labels=list(top_5.keys()),\n",
        "            autopct=\"%1.1f%%\",\n",
        "            colors=colors,\n",
        "            startangle=90,\n",
        "            textprops={\"fontsize\": 12, \"weight\": \"bold\"},\n",
        "            pctdistance=0.85,\n",
        "            wedgeprops=dict(width=0.5),  # make a donut\n",
        "        )\n",
        "\n",
        "        for autotext in autotexts:\n",
        "            autotext.set_color(\"white\")\n",
        "            autotext.set_fontsize(13)\n",
        "            autotext.set_weight(\"bold\")\n",
        "\n",
        "        plt.title(\"Top 5 Research Categories\", fontsize=16, fontweight=\"bold\", pad=20)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f\"{self.output_dir}/{filename}\", dpi=300, bbox_inches=\"tight\")\n",
        "        plt.close()\n",
        "        print(f\"  ‚úÖ {filename}\")\n",
        "\n",
        "    def generate_text_analysis(self, statistics: Dict, categorized: Dict) -> str:\n",
        "        \"\"\"\n",
        "        Generate textual analysis with the LLM.\n",
        "        \"\"\"\n",
        "        total_papers = sum(v[\"count\"] for v in statistics.values())\n",
        "\n",
        "        stats_text = \"\\n\".join(\n",
        "            [\n",
        "                f\"- {cat}: {data['count']} papers ({data['percentage']}%)\"\n",
        "                for cat, data in sorted(\n",
        "                    statistics.items(), key=lambda x: x[1][\"count\"], reverse=True\n",
        "                )\n",
        "                if data[\"count\"] > 0\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        prompt = f\"\"\"You are a research analyst specializing in Multi-Agent LLM Systems.\n",
        "\n",
        "Based on the following categorization of {total_papers} research papers from two major GitHub repositories:\n",
        "\n",
        "{stats_text}\n",
        "\n",
        "Please provide a comprehensive analysis in Persian (Farsi) covering:\n",
        "\n",
        "1. **ÿÆŸÑÿßÿµŸá ⁄©ŸÑ€å** (Overview):\n",
        "   - ÿ™ÿπÿØÿßÿØ ⁄©ŸÑ ŸÖŸÇÿßŸÑÿßÿ™ Ÿà ÿØÿ≥ÿ™Ÿá‚ÄåŸáÿß\n",
        "   - ÿ™Ÿàÿ≤€åÿπ ⁄©ŸÑ€å ÿ™ÿ≠ŸÇ€åŸÇÿßÿ™\n",
        "\n",
        "2. **ÿØÿ≥ÿ™Ÿá‚ÄåŸáÿß€å ÿßÿµŸÑ€å** (Main Categories):\n",
        "   - 5 ÿØÿ≥ÿ™Ÿá ÿ®ÿ±ÿ™ÿ± Ÿà ÿßŸáŸÖ€åÿ™ ÿ¢ŸÜŸáÿß\n",
        "   - ⁄Üÿ±ÿß ÿß€åŸÜ ÿØÿ≥ÿ™Ÿá‚ÄåŸáÿß Ÿæÿ±⁄©ÿßÿ±ÿ™ÿ± Ÿáÿ≥ÿ™ŸÜÿØÿü\n",
        "\n",
        "3. **ÿ±ŸàŸÜÿØŸáÿß€å ÿ™ÿ≠ŸÇ€åŸÇÿßÿ™€å** (Research Trends):\n",
        "   - ⁄©ÿØÿßŸÖ ÿ≠Ÿàÿ≤Ÿá‚ÄåŸáÿß ÿØÿßÿ∫‚Äåÿ™ÿ± Ÿáÿ≥ÿ™ŸÜÿØÿü\n",
        "   - ÿ¥⁄©ÿßŸÅ‚ÄåŸáÿß€å ÿ™ÿ≠ŸÇ€åŸÇÿßÿ™€å (⁄©ÿØÿßŸÖ ÿ≠Ÿàÿ≤Ÿá‚ÄåŸáÿß ⁄©ŸÖÿ™ÿ± ⁄©ÿßÿ± ÿ¥ÿØŸá‚ÄåÿßŸÜÿØ)\n",
        "\n",
        "4. **ŸÜ⁄©ÿßÿ™ ⁄©ŸÑ€åÿØ€å** (Key Insights):\n",
        "   - ⁄ÜŸá ÿßŸÑ⁄ØŸàŸáÿß€å€å ÿØÿ± ÿ™Ÿàÿ≤€åÿπ ŸÖÿ¥ÿßŸáÿØŸá ŸÖ€å‚Äåÿ¥ŸàÿØÿü\n",
        "   - ÿ™ŸÖÿ±⁄©ÿ≤ ÿ¨ÿßŸÖÿπŸá ÿ™ÿ≠ŸÇ€åŸÇÿßÿ™€å ÿ±Ÿà€å ⁄ÜŸá ŸÖÿ≥ÿßÿ¶ŸÑ€å ÿßÿ≥ÿ™ÿü\n",
        "\n",
        "5. **Ÿæ€åÿ¥ŸÜŸáÿßÿØÿßÿ™ ÿ®ÿ±ÿß€å Ÿæÿ±Ÿà⁄òŸá** (Recommendations):\n",
        "   - ÿ®ÿ±ÿß€å ŸÖÿ≠ŸÇŸÇ ŸÖÿ®ÿ™ÿØ€å ⁄©ÿØÿßŸÖ ÿØÿ≥ÿ™Ÿá ŸÖŸÜÿßÿ≥ÿ®‚Äåÿ™ÿ± ÿßÿ≥ÿ™ÿü\n",
        "   - ÿ≠Ÿàÿ≤Ÿá‚ÄåŸáÿß€å ŸÜŸàÿ∏ŸáŸàÿ± Ÿà ŸÅÿ±ÿµÿ™‚ÄåŸáÿß€å ÿ™ÿ≠ŸÇ€åŸÇÿßÿ™€å\n",
        "\n",
        "Write in a professional, academic Persian style. Be concise but insightful.\n",
        "Use proper Persian academic terminology. Keep it around 400-500 words.\"\"\"\n",
        "\n",
        "        print(\"  ü§ñ Generating analysis with LLM...\")\n",
        "        response = self.llm.invoke(prompt)\n",
        "        print(\"  ‚úÖ Textual analysis generated\")\n",
        "        return response.content\n",
        "\n",
        "    def generate_summary_table(self, statistics: Dict) -> str:\n",
        "        \"\"\"\n",
        "        Generate a text-based summary table.\n",
        "        \"\"\"\n",
        "        table = \"=\" * 90 + \"\\n\"\n",
        "        table += f\"{'Category':<45} {'Count':>12} {'Percentage':>18}\\n\"\n",
        "        table += \"=\" * 90 + \"\\n\"\n",
        "\n",
        "        sorted_stats = sorted(\n",
        "            statistics.items(), key=lambda x: x[1][\"count\"], reverse=True\n",
        "        )\n",
        "\n",
        "        for category, data in sorted_stats:\n",
        "            if data[\"count\"] > 0:\n",
        "                table += (\n",
        "                    f\"{category:<45} {data['count']:>12} \"\n",
        "                    f\"{data['percentage']:>17.2f}%\\n\"\n",
        "                )\n",
        "\n",
        "        table += \"=\" * 90 + \"\\n\"\n",
        "        total = sum(v[\"count\"] for v in statistics.values())\n",
        "        table += f\"{'TOTAL':<45} {total:>12} {'100.00%':>18}\\n\"\n",
        "        table += \"=\" * 90 + \"\\n\"\n",
        "\n",
        "        return table\n",
        "\n",
        "    def create_full_report(self, statistics: Dict, categorized: Dict):\n",
        "        \"\"\"\n",
        "        Create the full report (charts + text).\n",
        "        \"\"\"\n",
        "        print(\"\\n\" + \"=\" * 90)\n",
        "        print(\"üìä Agent 3 (Reporter) is generating the full report...\")\n",
        "        print(\"=\" * 90 + \"\\n\")\n",
        "\n",
        "        # Generate charts\n",
        "        print(\"üé® Drawing charts...\")\n",
        "        self.plot_bar_chart(statistics)\n",
        "        self.plot_pie_chart(statistics)\n",
        "        self.plot_horizontal_bar(statistics)\n",
        "        self.plot_treemap(statistics)\n",
        "        self.plot_percentage_comparison(statistics)\n",
        "        self.plot_top_categories_donut(statistics)\n",
        "        print()\n",
        "\n",
        "        # Textual analysis (LLM disabled here due to quota limits)\n",
        "        print(\"üìù Generating textual analysis...\")\n",
        "        # analysis = self.generate_text_analysis(statistics, categorized)\n",
        "        analysis = (\n",
        "            \"[LLM-based textual analysis is disabled in this notebook due to \"\n",
        "            \"quota limitations; the analysis will be written manually in the final report.]\"\n",
        "        )\n",
        "        # print(\"  ‚ö†Ô∏è LLM-based analysis not executed (quota limitation)\\n\")\n",
        "\n",
        "        # Summary table\n",
        "        summary_table = self.generate_summary_table(statistics)\n",
        "\n",
        "        # Build final report string\n",
        "        report = f\"\"\"\n",
        "{'=' * 90}\n",
        "MULTI-AGENT LLM RESEARCH ANALYSIS REPORT\n",
        "Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
        "Sources:\n",
        "  - https://github.com/kyegomez/awesome-multi-agent-papers\n",
        "  - https://github.com/shizhl/Multi-Agent-Papers\n",
        "{'=' * 90}\n",
        "\n",
        "{summary_table}\n",
        "\n",
        "{'=' * 90}\n",
        "DETAILED ANALYSIS (ÿ™ÿ≠ŸÑ€åŸÑ ÿ™ŸÅÿµ€åŸÑ€å)\n",
        "{'=' * 90}\n",
        "\n",
        "{analysis}\n",
        "\n",
        "{'=' * 90}\n",
        "VISUALIZATIONS\n",
        "{'=' * 90}\n",
        "\n",
        "The following charts have been generated in '{self.output_dir}/':\n",
        "\n",
        "1. bar_chart.png - Vertical bar chart showing paper distribution\n",
        "2. pie_chart.png - Pie chart showing top 8 categories + others\n",
        "3. horizontal_bar.png - Horizontal bar chart for easy comparison\n",
        "4. treemap.png - Treemap visualization of research areas\n",
        "5. percentage_chart.png - Dual comparison (percentage vs absolute count)\n",
        "6. donut_chart.png - Donut chart for top 5 categories\n",
        "\n",
        "{'=' * 90}\n",
        "METHODOLOGY\n",
        "{'=' * 90}\n",
        "\n",
        "This analysis was conducted using a Hybrid Multi-Agent System:\n",
        "\n",
        "Agent 1 (Extractor): Extracted paper titles from GitHub repositories\n",
        "Agent 2 (Categorizer): Used a hybrid approach (Keyword Matching + LLM)\n",
        "Agent 3 (Reporter): Generated visualizations and analysis\n",
        "\n",
        "Total Processing: ~5-7 minutes for ~500 papers\n",
        "\n",
        "{'=' * 90}\n",
        "END OF REPORT\n",
        "{'=' * 90}\n",
        "\"\"\"\n",
        "\n",
        "        # Save report to file\n",
        "        with open(f\"{self.output_dir}/full_report.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(report)\n",
        "\n",
        "        print(\"üíæ Reports have been saved:\")\n",
        "        print(f\"  ‚úÖ {self.output_dir}/full_report.txt\")\n",
        "\n",
        "        return report\n",
        "\n",
        "    def run(self, statistics: Dict, categorized: Dict):\n",
        "        \"\"\"\n",
        "        Run Agent 3 end-to-end.\n",
        "        \"\"\"\n",
        "        report = self.create_full_report(statistics, categorized)\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 90)\n",
        "        print(\"üéâ Agent 3 finished successfully!\")\n",
        "        print(\"=\" * 90)\n",
        "        print(f\"\\nüìÇ Output files in folder '{self.output_dir}':\\n\")\n",
        "        print(\"   üìä 6 high-quality charts\")\n",
        "        print(\"   üìÑ 1 comprehensive text report\")\n",
        "        print(\"   ü§ñ (Optional) LLM-generated analysis\\n\")\n",
        "\n",
        "        return report\n",
        "\n",
        "# ============================================================================\n",
        "# Run Agent 3\n",
        "# ============================================================================\n",
        "\n",
        "reporter = ReporterAgent(llm)\n",
        "final_report = reporter.run(statistics, categorized_papers)\n",
        "\n",
        "print(\"=\" * 90)\n",
        "print(\"üìÑ Report preview:\")\n",
        "print(\"=\" * 90)\n",
        "print(final_report[:1500] + \"\\n...\\n[continued in full_report.txt]\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OijmmCYkxXxK",
      "metadata": {
        "cellView": "form",
        "id": "OijmmCYkxXxK"
      },
      "outputs": [],
      "source": [
        "#@title extract data to drive\n",
        "# ÿßÿ®ÿ™ÿØÿß ŸæŸàÿ¥Ÿá Ÿæÿ±Ÿà⁄òŸá ÿ®ÿ≥ÿßÿ≤\n",
        "!mkdir -p \"/content/drive/MyDrive/project_phase1\"\n",
        "\n",
        "# ⁄©Ÿæ€å ŸáŸÖŸá ⁄Ü€åÿ≤ ÿ®Ÿá ÿ¨ÿ≤ .config Ÿà drive\n",
        "!cp -r /content/report_output \"/content/drive/MyDrive/project_phase1/\"\n",
        "!cp -r /content/sample_data \"/content/drive/MyDrive/project_phase1/\"\n",
        "!cp /content/*.json \"/content/drive/MyDrive/project_phase1/\"\n",
        "!cp /content/*.txt \"/content/drive/MyDrive/project_phase1/\"\n",
        "!cp /content/*.png \"/content/drive/MyDrive/project_phase1/\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YWBwyFNUyev8",
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWBwyFNUyev8",
        "outputId": "f1bad3e0-a7cc-4cee-96e2-90c9f2ac1ebf"
      },
      "outputs": [],
      "source": [
        "#@title mounting\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
